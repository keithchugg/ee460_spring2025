{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple XGBoost Example\n",
    "\n",
    "In this notebook, we show a very simple use pattern for XGBoost.  To run this, you need to 'pip install XGBoost' into your Python environment.\n",
    "\n",
    "author: Keith Chugg (chugg@usc.edu)\n",
    "\n",
    "ChatGPT was used in the generation of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Dataset\n",
    "\n",
    "* Source: Wisconsin Diagnostic Breast Cancer (WDBC) dataset\n",
    "* Task: Binary classification (malignant vs. benign breast cancer)\n",
    "* Features: 30 numerical features computed from digitized images of fine needle aspirates of breast masses\n",
    "* Samples: 569 instances\n",
    "* Classes:\n",
    "- 0 = Malignant (cancerous)\n",
    "- 1 = Benign (non-cancerous)\n",
    "\n",
    "More details:  https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: shape: (455, 30)\n",
      "X_test: shape: (114, 30)\n",
      "\n",
      "\n",
      "y_train: shape: (455,)\n",
      "y_test: shape: (114,)\n",
      "\n",
      "Classses:  {0, 1}\n",
      "Class 1 (Benign) examples in train: 286  or  62.86% \n",
      "Class 1 (Benign) examples in test: 71 or  62.28% \n"
     ]
    }
   ],
   "source": [
    "print(f'X_train: shape: {X_train.shape}')\n",
    "print(f'X_test: shape: {X_test.shape}\\n')\n",
    "\n",
    "print(f'y_train: shape: {y_train.shape}')\n",
    "print(f'y_test: shape: {y_test.shape}\\n')\n",
    "\n",
    "print(f'Classses:  {set(y_train)}')\n",
    "print(f'Class 1 (Benign) examples in train: {np.sum(y_train)}  or {100 * np.mean(y_train) : 2.2f}% ')\n",
    "print(f'Class 1 (Benign) examples in test: {np.sum(y_test)} or {100 * np.mean(y_test) : 2.2f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train an XGBoost classifier\n",
    "model = xgb.XGBClassifier(eval_metric=\"logloss\")\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mls23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
